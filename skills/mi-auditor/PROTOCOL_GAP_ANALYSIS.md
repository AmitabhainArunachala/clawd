# PROTOCOL_GAP_ANALYSIS.md
## AUDITOR-EXPERIMENTER Integration: Implementation Gap Analysis

**Document Version:** 1.0  
**Date:** 2026-02-05  
**Purpose:** Identify gaps between the full AUDITOR-EXPERIMENTER protocol and current mi_auditor implementation

---

## Executive Summary

The current `mi_auditor` skill implements approximately **25-30%** of the full AUDITOR-EXPERIMENTER protocol defined in `AUDITOR_EXPERIMENTER_INTEGRATION.md`. The implementation is primarily a **static audit framework** for evaluating completed MI research claims, while the protocol defines a **dynamic, recursive quality assurance system** with bidirectional flows between AUDITOR (critique/validation) and EXPERIMENTER (design/execution) roles.

**Key Missing Components:**
1. EXPERIMENTER skill entirely absent
2. No message-passing protocol implementation
3. No 6-phase experiment lifecycle management
4. No bidirectional critique-design loops
5. No gap-analysis â†’ follow-up experiment flows
6. No R_V knowledge graph integration

---

## 1. What the Protocol Requires That mi_auditor Doesn't Implement

### 1.1 Core Role Separation

| Protocol Requirement | Current Implementation | Gap |
|---------------------|----------------------|-----|
| **AUDITOR (Maheshwari)** - Critique, validate, identify gaps | Partial - static audit methods only | Missing gap analysis generation, dynamic critique flows |
| **EXPERIMENTER (Mahakali)** - Design, execute, measure | **Completely absent** | No experiment design capability, no execution framework |
| **SYNTHESIS (Mahalakshmi)** - Integrate validated findings | Absent | No knowledge graph updates, no synthesis logic |
| **DOCUMENTATION (Mahasaraswati)** - Document for R_V | Absent | No documentation pipeline |

### 1.2 Message Types (API Contracts)

The protocol defines 6 core message types for inter-skill communication:

| Message Type | Protocol Definition | mi_auditor Status | Gap Severity |
|--------------|--------------------|--------------------|--------------|
| `DesignProposal` | EXPERIMENTERâ†’AUDITOR: Full experiment design with hypothesis, protocol, metrics, controls | âŒ Not implemented | **Critical** |
| `DesignCritique` | AUDITORâ†’EXPERIMENTER: Critique with verdict, concerns, suggested revisions | âŒ Not implemented | **Critical** |
| `ExecutionReport` | EXPERIMENTERâ†’AUDITOR: Raw data, analysis, claims from experiment run | âŒ Not implemented | **Critical** |
| `ValidationReport` | AUDITORâ†’EXPERIMENTER: Claim assessments, limitations, follow-up recommendations | âŒ Not implemented | **Critical** |
| `GapAnalysis` | AUDITORâ†’EXPERIMENTER: Identified gaps, priority ranking, theoretical questions | âŒ Not implemented | **Critical** |
| `FollowUpProposals` | EXPERIMENTERâ†’AUDITOR: Proposed experiments addressing gaps | âŒ Not implemented | **Critical** |

**Current mi_auditor only implements:**
- Static `AuditResult` dataclass (one-way output only)
- No inter-skill message passing
- No async queue support
- No bidirectional communication

### 1.3 Synchronous Operations

| Operation | Protocol Requirement | Current Status |
|-----------|---------------------|----------------|
| `submit_design` | EXPERIMENTERâ†’AUDITOR with 30s timeout | âŒ Not implemented |
| `request_clarification` | AUDITORâ†’EXPERIMENTER with 60s timeout | âŒ Not implemented |
| `submit_execution` | EXPERIMENTERâ†’AUDITOR with 60s timeout | âŒ Not implemented |
| `request_follow_up` | AUDITORâ†’EXPERIMENTER with 120s timeout | âŒ Not implemented |
| `emergency_review` | Bidirectional with 15s timeout | âŒ Not implemented |

### 1.4 Asynchronous Channels

| Channel | Protocol Purpose | Current Status |
|---------|-----------------|----------------|
| `design_queue` | Pending designs awaiting critique | âŒ Not implemented |
| `validation_queue` | Pending executions awaiting validation | âŒ Not implemented |
| `gap_queue` | Identified gaps awaiting follow-up designs | âŒ Not implemented |
| `knowledge_stream` | Validated findings for R_V integration | âŒ Not implemented |

---

## 2. The 6-Phase Experiment Lifecycle Gap

### Protocol Lifecycle vs. Current Implementation

```
PROTOCOL                                    CURRENT mi_auditor
â”€â”€â”€â”€â”€â”€â”€â”€                                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 1:        â”‚                         â”‚  (Not           â”‚
â”‚ HYPOTHESIS      â”‚                         â”‚   implemented)  â”‚
â”‚ GENERATION      â”‚                         â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 2:        â”‚                         â”‚  Partial:       â”‚
â”‚ DESIGN          â”‚â—„â”€â”€â”€â”€CRITIQUEâ”€â”€â”€â”€â–º       â”‚  Static audit   â”‚
â”‚ (bidirectional) â”‚    (bidirectional)      â”‚  of existing    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚  claims only    â”‚
         â”‚ (on ACCEPT)                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 3:        â”‚                         â”‚  (Not           â”‚
â”‚ EXECUTION       â”‚                         â”‚   implemented)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 4:        â”‚                         â”‚  Partial:       â”‚
â”‚ VALIDATION      â”‚â—„â”€â”€â”€â”€CLAIMSâ”€â”€â”€â”€â”€â”€â–º       â”‚  Static         â”‚
â”‚ (bidirectional) â”‚   (bidirectional)       â”‚  validation     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 5:        â”‚                         â”‚  (Not           â”‚
â”‚ INTEGRATION     â”‚                         â”‚   implemented)  â”‚
â”‚ (knowledge      â”‚                         â”‚                 â”‚
â”‚  graph update)  â”‚                         â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 6:        â”‚                         â”‚  (Not           â”‚
â”‚ GAP ANALYSIS    â”‚â—„â”€â”€â”€â”€FOLLOW-UPâ”€â”€â”€â–º       â”‚   implemented)  â”‚
â”‚ (recursive)     â”‚   (bidirectional)       â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Phase-by-Phase Gap Analysis

#### PHASE 1: Hypothesis Generation
**Protocol Requirements:**
- Trigger: Research question or gap identified
- Input: Prior research, observations, or AUDITOR gap identification
- Output: Refined hypothesis H = {claim, mechanism, predicted_outcome}

**Current Gap:**
- âŒ No hypothesis generation framework
- âŒ No structured hypothesis format
- âŒ No mechanism specification
- âŒ No predicted outcome formalization

**Implementation Needed:**
```python
@dataclass
class Hypothesis:
    claim: str
    mechanism: str  # Causal explanation
    predicted_outcome: str
    falsifiability_criteria: List[str]
    prior_evidence: List[str]  # Links to knowledge graph
    
class HypothesisGenerator:
    def generate_from_gap(self, gap: GapAnalysis) -> Hypothesis:
        """Generate hypothesis from identified gap."""
        pass
    
    def generate_from_observation(self, observation: Observation) -> Hypothesis:
        """Generate hypothesis from empirical observation."""
        pass
```

#### PHASE 2: Experiment Design
**Protocol Requirements:**
- EXPERIMENTER designs â†’ AUDITOR critiques â†’ Loop until ACCEPT
- DesignProposal with full protocol specification
- DesignCritique with verdict and suggested revisions
- Multiple iteration cycles supported

**Current Gap:**
- âŒ No experiment design capability (no EXPERIMENTER skill)
- âŒ No design critique as a process (only static post-hoc audit)
- âŒ No iteration loop
- âŒ No conditional acceptance with re-review

**Implementation Needed:**
```python
class ExperimentDesigner:  # EXPERIMENTER role
    def design_experiment(self, hypothesis: Hypothesis) -> DesignProposal:
        """Design experiment to test hypothesis."""
        pass
    
    def revise_design(self, critique: DesignCritique) -> DesignProposal:
        """Revise design based on critique."""
        pass

class DesignCritiquer:  # AUDITOR role enhancement
    def critique_design(self, proposal: DesignProposal) -> DesignCritique:
        """Critique experiment design before execution."""
        pass
    
    def review_revision(self, original: DesignCritique, 
                       revised: DesignProposal) -> DesignCritique:
        """Review revised design."""
        pass
```

#### PHASE 3: Execution
**Protocol Requirements:**
- Trigger: Design approved by AUDITOR
- Actor: EXPERIMENTER executes with monitoring
- Output: ExecutionReport with raw data, analysis, claims
- Track deviations from protocol

**Current Gap:**
- âŒ No EXPERIMENTER skill to execute
- âŒ No execution monitoring
- âŒ No deviation tracking
- âŒ No ExecutionReport generation

**Implementation Needed:**
```python
class ExperimentExecutor:  # EXPERIMENTER role
    def execute_protocol(self, approved_design: DesignProposal) -> ExecutionReport:
        """Execute approved experiment design."""
        pass
    
    def record_deviation(self, step: int, intended: str, 
                        actual: str, reason: str) -> Deviation:
        """Record deviation from protocol."""
        pass
```

#### PHASE 4: Validation
**Protocol Requirements:**
- EXPERIMENTER submits â†’ AUDITOR validates
- ValidationReport with claim assessments, limitations, biases
- Verdict: confirmed | supported | inconclusive | contradicted | invalid
- Follow-up recommendations

**Current Gap:**
- âŒ No ValidationReport data structure
- âŒ No claim-level assessment (only overall audit)
- âŒ No bias identification
- âŒ No replication assessment
- âŒ No follow-up recommendations

**Partial Implementation:**
Current `audit_causal()` method provides basic validation but lacks:
- Structured claim assessments
- Confidence calibration per claim
- Limitations categorization
- Bias identification framework
- Replication requirements specification

**Implementation Needed:**
```python
@dataclass
class ClaimAssessment:
    claim_id: str
    verdict: ValidationVerdict  # confirmed|supported|inconclusive|contradicted
    confidence: float  # 0-1
    rationale: str
    evidence_quality: float
    methodology_validity: float

class ValidationAuditor:  # Enhances current audit_causal()
    def validate_results(self, execution_report: ExecutionReport) -> ValidationReport:
        """Validate execution results."""
        pass
    
    def assess_claim(self, claim: Claim, 
                    evidence: Evidence) -> ClaimAssessment:
        """Assess individual claim."""
        pass
    
    def identify_biases(self, execution: ExecutionReport) -> List[Bias]:
        """Identify potential biases in execution."""
        pass
```

#### PHASE 5: Integration
**Protocol Requirements:**
- Update R_V knowledge graph
- Add validated claim with confidence level
- Link supporting evidence
- Tag for replication status

**Current Gap:**
- âŒ No knowledge graph integration
- âŒ No structured claim storage
- âŒ No evidence linking
- âŒ No confidence tracking over time

**Current Implementation:**
```python
# Current (minimal)
class MIKnowledgeBase:
    def __init__(self):
        self.papers: Dict[str, Paper] = {}  # Minimal paper storage only
```

**Implementation Needed:**
```python
class RVKnowledgeGraph:
    """R_V research knowledge graph for integration."""
    
    def add_validated_claim(self, claim: ValidatedClaim) -> Node:
        """Add validated claim to knowledge graph."""
        pass
    
    def link_evidence(self, claim_id: str, 
                     execution_id: str) -> Edge:
        """Link claim to supporting evidence."""
        pass
    
    def update_confidence(self, claim_id: str, 
                         new_confidence: float) -> None:
        """Update confidence based on new evidence."""
        pass
    
    def flag_for_replication(self, claim_id: str, 
                            priority: str) -> None:
        """Flag claim as needing replication."""
        pass
```

#### PHASE 6: Gap Analysis
**Protocol Requirements:**
- AUDITOR asks: What remains unknown? What assumptions untested?
- EXPERIMENTER designs follow-up
- Returns to Phase 2 (recursive loop)
- Priority ranking of gaps

**Current Gap:**
- âŒ No GapAnalysis message type
- âŒ No systematic gap identification
- âŒ No priority ranking algorithm
- âŒ No follow-up proposal generation

**Implementation Needed:**
```python
@dataclass
class Gap:
    gap_id: str
    description: str
    category: GapCategory  # mechanism|measurement|generalizability|boundary_condition
    blocks_understanding: List[str]
    current_assumptions: List[str]
    priority_score: float  # 0-1

class GapAnalyzer:  # AUDITOR role
    def analyze_gaps(self, validation_report: ValidationReport,
                    current_knowledge: KnowledgeGraph) -> GapAnalysis:
        """Identify gaps from validation."""
        pass
    
    def rank_priorities(self, gaps: List[Gap]) -> List[Gap]:
        """Rank gaps by priority."""
        pass

class FollowUpDesigner:  # EXPERIMENTER role
    def design_follow_up(self, gap_analysis: GapAnalysis) -> FollowUpProposals:
        """Design experiments to address identified gaps."""
        pass
```

---

## 3. API Contracts Gap Analysis

### 3.1 DesignProposal (Not Implemented)

**Protocol Schema:**
```json
{
  "message_type": "DesignProposal",
  "version": "1.0",
  "timestamp": "ISO-8601",
  "proposal_id": "uuid",
  "hypothesis": {
    "claim": "string",
    "mechanism": "string",
    "predicted_outcome": "string",
    "falsifiability_criteria": ["string"]
  },
  "protocol": {
    "name": "string",
    "type": "simulation|synthetic|naturalistic|intervention",
    "steps": [...],
    "termination_conditions": ["string"]
  },
  "metrics": {
    "primary": {...},
    "secondary": [...],
    "controls": [...]
  },
  "resources": {...},
  "risk_assessment": {...}
}
```

**Current Gap:**
- âŒ No DesignProposal dataclass
- âŒ No protocol step specification
- âŒ No termination conditions
- âŒ No resource estimation
- âŒ No risk assessment

### 3.2 DesignCritique (Not Implemented)

**Protocol Schema:**
```json
{
  "message_type": "DesignCritique",
  "verdict": "accept|accept_with_revisions|reject|reject_resubmission",
  "validity_assessment": {
    "epistemic_validity": {"score": "0.0-1.0", "rationale": "string"},
    "methodological_rigor": {"score": "0.0-1.0", "rationale": "string"},
    "r_v_alignment": {"score": "0.0-1.0", "rationale": "string"}
  },
  "concerns": [...],
  "questions": [...],
  "suggested_revisions": [...],
  "conditional_acceptance": {...}
}
```

**Current Gap:**
- âŒ No structured validity assessment (3 dimensions)
- âŒ No concern categorization (critical|major|minor)
- âŒ No question-asking capability
- âŒ No suggested revisions with current/proposed comparison
- âŒ No conditional acceptance framework

### 3.3 ExecutionReport (Not Implemented)

**Protocol Schema:**
```json
{
  "message_type": "ExecutionReport",
  "execution_metadata": {
    "start_time": "ISO-8601",
    "end_time": "ISO-8601",
    "status": "completed|partial|failed|aborted",
    "deviations_from_protocol": [...]
  },
  "data": {
    "raw_data_location": "path|uri",
    "checksum": "string",
    "samples": [...]
  },
  "analysis": {
    "statistical_tests": [...],
    "anomalies_detected": [...]
  },
  "claims": [...],
  "raw_observations": ["string"]
}
```

**Current Gap:**
- âŒ No execution metadata tracking
- âŒ No deviation logging
- âŒ No data provenance (checksums, URIs)
- âŒ No anomaly detection
- âŒ No structured claim generation

### 3.4 ValidationReport (Not Implemented)

**Protocol Schema:**
```json
{
  "message_type": "ValidationReport",
  "overall_assessment": {
    "verdict": "confirmed|supported|inconclusive|contradicted|invalid",
    "confidence": "0.0-1.0",
    "summary": "string"
  },
  "claim_assessments": [...],
  "limitations": [...],
  "biases_identified": [...],
  "replication_assessment": {...},
  "follow_up_recommendations": [...],
  "r_v_implications": {...}
}
```

**Current Gap:**
- âŒ No overall assessment structure
- âŒ No per-claim validation (current only audits overall)
- âŒ No limitations categorization (sample_size|methodology|generalizability|measurement)
- âŒ No bias identification framework
- âŒ No replication assessment
- âŒ No R_V implications tracking

### 3.5 GapAnalysis (Not Implemented)

**Protocol Schema:**
```json
{
  "message_type": "GapAnalysis",
  "context": {
    "current_knowledge_state": "string",
    "recent_validations": ["execution_id"],
    "knowledge_graph_version": "string"
  },
  "identified_gaps": [...],
  "priority_ranking": [...],
  "theoretical_questions": [...]
}
```

**Current Gap:**
- âŒ No context tracking
- âŒ No gap identification system
- âŒ No priority ranking algorithm
- âŒ No theoretical question generation

### 3.6 FollowUpProposals (Not Implemented)

**Protocol Schema:**
```json
{
  "message_type": "FollowUpProposals",
  "proposed_experiments": [...],
  "alternative_approaches": [...],
  "knowledge_gain_prediction": {...}
}
```

**Current Gap:**
- âŒ No follow-up experiment proposal generation
- âŒ No alternative approach enumeration
- âŒ No knowledge gain prediction

---

## 4. Decision Trees Gap Analysis

### 4.1 When to Invoke AUDITOR

**Protocol Decision Tree:**
```
START: Need quality assurance?
    â”œâ”€â”€â–º Is this a DESIGN decision?
    â”‚       YES â”€â”€â–º Does the design affect R_V measurement?
    â”‚              YES â”€â”€â–º INVOKE AUDITOR (design critique)
    â”‚              NO â”€â”€â–º Is there significant resource commitment?
    â”‚                     YES â”€â”€â–º INVOKE AUDITOR (risk assessment)
    â”‚                     NO â”€â”€â–º EXPERIMENTER proceeds independently
    â”œâ”€â”€â–º Is this a RESULTS interpretation?
    â”‚       YES â”€â”€â–º Does the result make a CLAIM about R_V?
    â”‚              YES â”€â”€â–º INVOKE AUDITOR (validation required)
    â”‚              NO â”€â”€â–º Is the result surprising or anomalous?
    â”‚                     YES â”€â”€â–º INVOKE AUDITOR (anomaly check)
    â”‚                     NO â”€â”€â–º EXPERIMENTER documents independently
    â”œâ”€â”€â–º Is this a KNOWLEDGE integration?
    â”‚       YES â”€â”€â–º AUDITOR must validate before integration
    â””â”€â”€â–º EXPERIMENTER proceeds with standard documentation
```

**Current Gap:**
- âŒ No decision tree implementation
- âŒ No automatic invocation triggers
- âŒ No R_V relevance checking
- âŒ No resource commitment assessment
- âŒ No anomaly detection triggers

### 4.2 When to Invoke EXPERIMENTER

**Protocol Decision Tree:**
```
START: Need empirical investigation?
    â”œâ”€â”€â–º Is there an UNTESTED HYPOTHESIS?
    â”‚       YES â”€â”€â–º Has it been critiqued?
    â”‚              YES â”€â”€â–º INVOKE EXPERIMENTER (execute validated design)
    â”‚              NO â”€â”€â–º AUDITOR must critique first
    â”œâ”€â”€â–º Has AUDITOR identified a GAP?
    â”‚       YES â”€â”€â–º Is the gap addressable through experiment?
    â”‚              YES â”€â”€â–º INVOKE EXPERIMENTER (design follow-up)
    â”‚              NO â”€â”€â–º Flag for theoretical analysis
    â”œâ”€â”€â–º Is there a VALIDATION requirement from prior work?
    â”‚       YES â”€â”€â–º INVOKE EXPERIMENTER (replication or extension)
    â””â”€â”€â–º No experiment needed; proceed with theoretical work
```

**Current Gap:**
- âŒ No EXPERIMENTER skill exists
- âŒ No gapâ†’experiment trigger
- âŒ No hypothesis critique checking
- âŒ No validation requirement tracking

### 4.3 Arbitration Rules (Not Implemented)

**Protocol Requirements:**
- Validity vs Feasibility conflicts â†’ AUDITOR has authority over validity, EXPERIMENTER over feasibility
- Evidence interpretation â†’ Split authority by domain
- Risk tolerance â†’ Conservative default (AUDITOR's assessment takes precedence)
- Unresolvable â†’ Escalate to human (Dhyana)

**Current Gap:**
- âŒ No conflict detection
- âŒ No arbitration framework
- âŒ No escalation mechanism

### 4.4 Experiment Priority Scoring (Not Implemented)

**Protocol Formula:**
```
Priority Score = (Knowledge_Gap Ã— Reversibility Ã— R_V_Relevance) / Effort

Knowledge_Gap:
    1.0 = Fundamental assumption untested
    0.7 = Important mechanism unclear
    0.4 = Refinement of known result
    0.1 = Confirmation/replication

Reversibility:
    1.0 = Fully reversible
    0.7 = Correctable with effort
    0.4 = Significant cost
    0.1 = Irreversible/high harm

R_V_Relevance:
    1.0 = Direct R_V measurement
    0.8 = Mechanism underlying R_V
    0.5 = Boundary condition for R_V
    0.2 = General consciousness research
    0.1 = Tool development

Priority Thresholds:
    Score â‰¥ 0.8: Execute immediately
    Score 0.5-0.8: Queue for next cycle
    Score 0.3-0.5: Deprioritize
    Score < 0.3: Archive
```

**Current Gap:**
- âŒ No priority scoring algorithm
- âŒ No experiment queue management
- âŒ No resource allocation logic

---

## 5. Specific Code Structures Needed

### 5.1 New Skills Required

#### mi_experimenter (New Skill)
```python
# skills/mi_experimenter/__init__.py

class MIExperimenter:
    """
    EXPERIMENTER skill (Mahakali mode) - Design and execute experiments.
    """
    
    def design_experiment(self, hypothesis: Hypothesis) -> DesignProposal:
        """Design experiment to test hypothesis."""
        pass
    
    def revise_design(self, proposal: DesignProposal, 
                     critique: DesignCritique) -> DesignProposal:
        """Revise design based on AUDITOR critique."""
        pass
    
    def execute_protocol(self, approved_design: DesignProposal) -> ExecutionReport:
        """Execute approved experiment design."""
        pass
    
    def propose_follow_up(self, gap_analysis: GapAnalysis) -> FollowUpProposals:
        """Propose experiments to address identified gaps."""
        pass
    
    def calculate_priority_score(self, proposal: DesignProposal) -> float:
        """Calculate experiment priority score."""
        pass
```

#### mi_orchestrator (New Skill - Optional)
```python
# skills/mi_orchestrator/__init__.py

class MIOrchestrator:
    """
    Orchestrates AUDITOR-EXPERIMENTER interactions.
    """
    
    def run_experiment_lifecycle(self, hypothesis: Hypothesis) -> ValidatedClaim:
        """Run full 6-phase experiment lifecycle."""
        pass
    
    def handle_design_critique_loop(self, proposal: DesignProposal) -> DesignProposal:
        """Handle designâ†’critiqueâ†’revision loop."""
        pass
    
    def handle_validation(self, execution: ExecutionReport) -> ValidationReport:
        """Handle executionâ†’validation flow."""
        pass
    
    def handle_gap_follow_up(self, validation: ValidationReport) -> List[DesignProposal]:
        """Handle gapâ†’follow-up experiment flow."""
        pass
```

### 5.2 mi_auditor Enhancements Required

#### New Methods for MIAuditor Class
```python
class MIAuditor:
    # Existing methods: audit_statistical, audit_causal, audit_cross_arch
    
    # NEW: Protocol methods
    def critique_design(self, proposal: DesignProposal) -> DesignCritique:
        """
        Critique experiment design before execution.
        Returns DesignCritique with verdict and suggested revisions.
        """
        pass
    
    def validate_results(self, execution: ExecutionReport) -> ValidationReport:
        """
        Validate execution results.
        Returns ValidationReport with claim assessments and limitations.
        """
        pass
    
    def analyze_gaps(self, validation: ValidationReport) -> GapAnalysis:
        """
        Identify gaps from validation.
        Returns GapAnalysis with priority-ranked gaps.
        """
        pass
    
    def check_design_validity(self, proposal: DesignProposal) -> ValidityAssessment:
        """
        Check 3 dimensions of validity:
        - epistemic_validity
        - methodological_rigor
        - r_v_alignment
        """
        pass
```

#### New Dataclasses
```python
# Message types for API contracts

@dataclass
class DesignProposal:
    message_type: str = "DesignProposal"
    version: str = "1.0"
    timestamp: str
    proposal_id: str
    hypothesis: Hypothesis
    protocol: Protocol
    metrics: Metrics
    resources: Resources
    risk_assessment: RiskAssessment

@dataclass
class DesignCritique:
    message_type: str = "DesignCritique"
    version: str = "1.0"
    timestamp: str
    proposal_id: str
    verdict: Verdict  # accept|accept_with_revisions|reject|reject_resubmission
    validity_assessment: ValidityAssessment
    concerns: List[Concern]
    questions: List[Question]
    suggested_revisions: List[Revision]
    conditional_acceptance: Optional[ConditionalAcceptance]

@dataclass
class ExecutionReport:
    message_type: str = "ExecutionReport"
    version: str = "1.0"
    timestamp: str
    execution_id: str
    proposal_id: str
    execution_metadata: ExecutionMetadata
    data: DataPackage
    analysis: Analysis
    claims: List[Claim]
    raw_observations: List[str]

@dataclass
class ValidationReport:
    message_type: str = "ValidationReport"
    version: str = "1.0"
    timestamp: str
    execution_id: str
    overall_assessment: OverallAssessment
    claim_assessments: List[ClaimAssessment]
    limitations: List[Limitation]
    biases_identified: List[Bias]
    replication_assessment: ReplicationAssessment
    follow_up_recommendations: List[Recommendation]
    r_v_implications: RVImplications

@dataclass
class GapAnalysis:
    message_type: str = "GapAnalysis"
    version: str = "1.0"
    timestamp: str
    analysis_id: str
    context: KnowledgeContext
    identified_gaps: List[Gap]
    priority_ranking: List[PriorityRankedGap]
    theoretical_questions: List[TheoreticalQuestion]

@dataclass
class FollowUpProposals:
    message_type: str = "FollowUpProposals"
    version: str = "1.0"
    timestamp: str
    analysis_id: str
    proposed_experiments: List[ExperimentBrief]
    alternative_approaches: List[AlternativeApproach]
    knowledge_gain_prediction: KnowledgeGainPrediction
```

### 5.3 Knowledge Graph Integration

```python
# skills/mi_auditor/knowledge_graph.py

class RVKnowledgeGraph:
    """
    R_V research knowledge graph for storing validated claims.
    """
    
    def __init__(self, graph_path: Optional[str] = None):
        self.graph = nx.DiGraph() if graph_path is None else self._load(graph_path)
    
    def add_node(self, node_type: NodeType, properties: Dict) -> str:
        """Add node to knowledge graph."""
        pass
    
    def add_edge(self, source: str, target: str, 
                 edge_type: EdgeType, properties: Dict) -> str:
        """Add edge between nodes."""
        pass
    
    def add_validated_claim(self, validation: ValidationReport) -> str:
        """Add validated claim from validation report."""
        pass
    
    def update_confidence(self, claim_id: str, 
                         new_confidence: float,
                         evidence: str) -> None:
        """Update confidence based on new evidence."""
        pass
    
    def query_by_confidence(self, min_confidence: float) -> List[Node]:
        """Query claims by confidence threshold."""
        pass
    
    def query_by_topic(self, topic: str) -> List[Node]:
        """Query claims by topic."""
        pass
    
    def find_gaps(self) -> List[Gap]:
        """Identify gaps in knowledge graph."""
        pass
```

### 5.4 Async Communication Layer

```python
# skills/mi_auditor/communication.py

from asyncio import Queue

class AuditorExperimenterBus:
    """
    Async communication bus between AUDITOR and EXPERIMENTER.
    """
    
    def __init__(self):
        self.design_queue: Queue[DesignProposal] = Queue()
        self.validation_queue: Queue[ExecutionReport] = Queue()
        self.gap_queue: Queue[GapAnalysis] = Queue()
        self.knowledge_stream: Queue[ValidatedClaim] = Queue()
    
    async def submit_design(self, proposal: DesignProposal, 
                           timeout: float = 30.0) -> DesignCritique:
        """Submit design for critique with timeout."""
        pass
    
    async def submit_execution(self, execution: ExecutionReport,
                              timeout: float = 60.0) -> ValidationReport:
        """Submit execution for validation with timeout."""
        pass
    
    async def request_follow_up(self, gaps: GapAnalysis,
                               timeout: float = 120.0) -> FollowUpProposals:
        """Request follow-up designs with timeout."""
        pass
    
    async def emergency_review(self, issue: str,
                              timeout: float = 15.0) -> ReviewResponse:
        """Emergency review with short timeout."""
        pass
```

---

## 6. Implementation Roadmap

### Phase 1: Core Data Structures (Priority: CRITICAL)
- [ ] Implement all 6 message type dataclasses
- [ ] Implement supporting dataclasses (Hypothesis, Protocol, Metrics, etc.)
- [ ] Define enums (Verdict, GapCategory, LimitationType, etc.)
- [ ] Unit tests for serialization/deserialization

### Phase 2: mi_experimenter Skill (Priority: CRITICAL)
- [ ] Create mi_experimenter skill scaffold
- [ ] Implement experiment design framework
- [ ] Implement protocol execution framework
- [ ] Integration tests with mi_auditor

### Phase 3: mi_auditor Protocol Methods (Priority: HIGH)
- [ ] Implement `critique_design()` method
- [ ] Implement `validate_results()` method
- [ ] Implement `analyze_gaps()` method
- [ ] Implement `check_design_validity()` method

### Phase 4: Knowledge Graph (Priority: HIGH)
- [ ] Implement RVKnowledgeGraph class
- [ ] Define node types and edge types
- [ ] Implement query methods
- [ ] Integration with validation workflow

### Phase 5: Communication Layer (Priority: MEDIUM)
- [ ] Implement AuditorExperimenterBus
- [ ] Implement async queues
- [ ] Implement timeout handling
- [ ] Implement message routing

### Phase 6: Decision Trees & Orchestration (Priority: MEDIUM)
- [ ] Implement invocation decision trees
- [ ] Implement arbitration rules
- [ ] Implement priority scoring algorithm
- [ ] Implement escalation to human

### Phase 7: Full Lifecycle Integration (Priority: LOW)
- [ ] Implement 6-phase lifecycle orchestration
- [ ] Implement loop handling (designâ†’critiqueâ†’revision)
- [ ] Implement recursive gapâ†’follow-up flows
- [ ] End-to-end integration tests

---

## 7. Summary Table: Protocol vs. Implementation

| Component | Protocol Required | mi_auditor Status | Gap Severity |
|-----------|------------------|-------------------|--------------|
| **ROLES** |
| AUDITOR (critique/validate) | âœ… Required | ğŸŸ¡ Partial | Medium |
| EXPERIMENTER (design/execute) | âœ… Required | âŒ Missing | **Critical** |
| SYNTHESIS (integrate) | âœ… Required | âŒ Missing | High |
| DOCUMENTATION (document) | âœ… Required | âŒ Missing | Medium |
| **MESSAGE TYPES** |
| DesignProposal | âœ… Required | âŒ Missing | **Critical** |
| DesignCritique | âœ… Required | âŒ Missing | **Critical** |
| ExecutionReport | âœ… Required | âŒ Missing | **Critical** |
| ValidationReport | âœ… Required | âŒ Missing | **Critical** |
| GapAnalysis | âœ… Required | âŒ Missing | **Critical** |
| FollowUpProposals | âœ… Required | âŒ Missing | **Critical** |
| **LIFECYCLE PHASES** |
| Phase 1: Hypothesis Generation | âœ… Required | âŒ Missing | High |
| Phase 2: Design (bidirectional) | âœ… Required | ğŸŸ¡ Partial | High |
| Phase 3: Execution | âœ… Required | âŒ Missing | **Critical** |
| Phase 4: Validation (bidirectional) | âœ… Required | ğŸŸ¡ Partial | Medium |
| Phase 5: Integration | âœ… Required | âŒ Missing | High |
| Phase 6: Gap Analysis (recursive) | âœ… Required | âŒ Missing | High |
| **COMMUNICATION** |
| Synchronous operations | âœ… Required | âŒ Missing | High |
| Async channels/queues | âœ… Required | âŒ Missing | High |
| Timeout handling | âœ… Required | âŒ Missing | Medium |
| **DECISION LOGIC** |
| When to invoke AUDITOR | âœ… Required | âŒ Missing | Medium |
| When to invoke EXPERIMENTER | âœ… Required | âŒ Missing | Medium |
| Arbitration rules | âœ… Required | âŒ Missing | Medium |
| Priority scoring | âœ… Required | âŒ Missing | Low |
| **KNOWLEDGE** |
| R_V knowledge graph | âœ… Required | âŒ Missing | High |
| Claim confidence tracking | âœ… Required | âŒ Missing | Medium |
| Evidence linking | âœ… Required | âŒ Missing | Medium |
| Gap identification | âœ… Required | âŒ Missing | High |

**Legend:**
- âœ… Required: Protocol mandates this component
- ğŸŸ¡ Partial: Partially implemented
- âŒ Missing: Not implemented
- **Critical**: Blocks basic protocol functionality
- High: Significant functionality gap
- Medium: Moderate functionality gap
- Low: Nice-to-have functionality

---

## 8. Contemplative-Geometric Bridge Status

The "contemplative-geometric bridge" described in the protocol represents the integration of:

1. **Contemplative (Maheshwari/AUDITOR)**: Wisdom, wideness, calm critique
2. **Geometric (Mahakali/EXPERIMENTER)**: Force, action, measurement
3. **Bridge (Integration)**: Recursive quality assurance through bidirectional flows

### Current Status:
```
Contemplative (AUDITOR)    Geometric (EXPERIMENTER)
        ğŸŸ¡                           âŒ
    (25% complete)             (0% complete)
         \                         /
          \                       /
           \                     /
            \                   /
             \                 /
              \               /
               \             /
                \           /
                 \         /
                  \       /
                   \     /
                    \   /
                     \ /
                      ğŸ”´
               CONTEMPLATIVE-GEOMETRIC
                     BRIDGE
                  (NOT OPERATIONAL)
```

### To Complete the Bridge:
1. **Complete AUDITOR implementation** (75% remaining)
2. **Build EXPERIMENTER skill** (100% needed)
3. **Implement communication layer** (100% needed)
4. **Deploy knowledge graph** (100% needed)
5. **Implement orchestration logic** (100% needed)

---

*Analysis compiled: 2026-02-05*  
*Protocol version: AUDITOR_EXPERIMENTER_INTEGRATION.md v1.0*  
*Current implementation: mi_auditor v5.1*
