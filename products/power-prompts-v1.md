# Power Prompts Pack v1
## 47 Battle-Tested Prompts for Knowledge Workers

**Price: $9**  
**Format: Markdown + Copy-Paste Ready**  
**Last Updated: 2026-02-10**

---

## What's Inside

This isn't a list of "creative writing starters." These are **system prompts** — the hidden instructions that shape how AI thinks before it responds to you. Used correctly, they transform generic outputs into specialized expertise.

Each prompt includes:
- The exact text to use
- When to deploy it
- Expected output format
- Pro tips from 6 months of daily use

---

## Category 1: Thinking Modes (7 prompts)

### 1. The Steel-Man Protocol
**Use when:** You need the strongest version of an opposing argument

```
You are my intellectual sparring partner. Your task is to construct the strongest possible version of the opposing view to [MY POSITION]. Do not strawman. Do not weaken for rhetorical effect. If the opposing view has merit, acknowledge it. If my position is weak, show me exactly where. Your goal is not to win—it's to help me stress-test my thinking.
```

**Expected output:** Bullet-pointed argument map with premises, inferences, and potential rebuttals.

**Pro tip:** Run this twice—once for the opposition, once for your own view. Compare gaps.

---

### 2. The Recursive Analyst
**Use when:** You're stuck in surface-level analysis

```
Analyze [TOPIC] through five levels of depth:

Level 1 - Observable facts
Level 2 - Immediate implications  
Level 3 - Systemic patterns
Level 4 - Structural assumptions
Level 5 - Invariant principles

At each level, identify:
- What's visible at this layer
- What becomes invisible
- The transition logic to the next level

Stop when you reach diminishing returns, but push at least one level past comfort.
```

**Expected output:** Hierarchical breakdown with explicit transition logic between levels.

---

### 3. The Pre-Mortem Engine
**Use when:** Planning something important

```
We're 6 months in the future. [PROJECT/PLAN] has failed catastrophically. Not mildly—spectacularly. Walk me through exactly what went wrong. Be specific: which assumption proved false? Which risk materialized? Which person dropped which ball? What warning signs did we ignore in week 2 that became obvious in hindsight?

Then: What would we need to monitor now to detect these failure modes early?
```

**Expected output:** Narrative failure scenario followed by early-warning indicators.

**Pro tip:** The more vivid the failure scenario, the more actionable the prevention.

---

### 4. The Constraint Finder
**Use when:** You need to know what's actually limiting you

```
For [SITUATION], identify the binding constraint using the Theory of Constraints framework:

1. List all potential constraints (resources, knowledge, time, permissions, skills, motivation)
2. For each, ask: If this were infinite, would output increase?
3. Identify the single constraint where elevation would unlock flow
4. Ignore the others for now—subordinate everything else to this constraint
5. Define: How will we elevate it? What does "good enough" look like?
```

**Expected output:** Ranked constraint list with one clear primary constraint and elevation plan.

---

### 5. The Decision Journal
**Use when:** Making irreversible decisions

```
Help me document this decision for later review:

Context: [SITUATION]
Decision: [WHAT I'M CHOOSING]
Alternatives considered: [OTHER OPTIONS]
Expected outcome: [WHAT I PREDICT WILL HAPPEN]
Confidence level: [1-10]
Key assumptions: [WHAT MUST BE TRUE FOR THIS TO WORK]
What would change my mind: [EVIDENCE THAT WOULD REVERSE THIS DECISION]
Timestamp: [NOW]
Review date: [WHEN TO CHECK IF PREDICTION WAS ACCURATE]
```

**Expected output:** Structured decision record suitable for future calibration review.

---

### 6. The Red Team
**Use when:** You think you've solved a hard problem

```
I've developed [SOLUTION] for [PROBLEM]. Your job is to break it. Find edge cases, hidden assumptions, failure modes I haven't considered. Attack the foundations, not the implementation. If the approach is fundamentally flawed, I need to know now—not after I've built it.

Be ruthless but constructive. For each flaw, suggest if it's fixable or fatal.
```

**Expected output:** Critical analysis categorized as: Fatal Flaws / Fixable Issues / Edge Cases / Unaddressed Assumptions.

---

### 7. The Synthesis Engine
**Use when:** You've gathered too much information and need coherence

```
I have the following inputs: [PASTE NOTES/RESEARCH/IDEAS]

Synthesize these into:
1. Core insight (the one thing that matters most)
2. Supporting structure (3-5 key pillars)
3. Tensions or contradictions (what doesn't fit)
4. Actionable implications (what to do differently)
5. What remains unknown (explicit gaps)

Optimize for clarity over completeness. If the synthesis requires discarding 80% of the inputs, do it.
```

**Expected output:** Concise synthesis with explicit trade-offs acknowledged.

---

## Category 2: Content Creation (10 prompts)

### 8. The Expert Translator
**Use when:** Writing for non-experts about expert topics

```
Explain [COMPLEX TOPIC] to [AUDIENCE] who knows [BACKGROUND LEVEL].

Rules:
- No jargon without immediate translation
- Use analogies from their domain
- Structure: What → So What → Now What
- Every paragraph must answer: "Why should I care?"
- Include one "aha" moment they can share at dinner
```

**Expected output:** Accessible explanation with clear relevance hooks.

---

### 9. The Hook Generator
**Use when:** Your opening is weak

```
Generate 10 opening hooks for [TOPIC]:

Mix these types:
- 2 Contrarian (everyone thinks X, but...)
- 2 Specific/Concrete (the exact number/moment)
- 2 Story-driven (one person's transformation)
- 2 Question (makes reader need to know)
- 2 Pattern interruption (unexpected format)

Each hook must:
- Create immediate curiosity gap
- Promise specific value
- Be under 25 words
```

**Expected output:** 10 varied hooks ready for A/B testing.

---

### 10. The Voice Mirror
**Use when:** You need to match a specific writing style

```
Analyze this writing sample: [PASTE 200-500 WORDS]

Extract:
- Sentence length patterns (short/medium/long ratio)
- Vocabulary level (concrete vs abstract preference)
- Transition style (how ideas connect)
- Rhythm (pacing, paragraph length variation)
- Attitude (authoritative, humble, playful, etc.)

Then write [NEW CONTENT] in this exact voice. Don't explain the analysis—just execute.
```

**Expected output:** New content that stylistically matches the sample.

---

### 11. The Cut Editor
**Use when:** Your draft is too long

```
Cut this by 50% without losing meaning: [PASTE TEXT]

Rules:
- Remove hedging ("I think", "perhaps", "it seems")
- Delete throat-clearing ("In today's world...")
- Kill adverbs replacing weak verbs
- Merge redundant sentences
- Preserve the core insight—kill everything else

Show before/after word count.
```

**Expected output:** Tightened text with explicit compression ratio.

---

### 12. The Structure Architect
**Use when:** Starting a long piece without a map

```
Create an outline for [TOPIC] targeting [LENGTH] words.

Structure using:
- Opening: Problem + Promise (10%)
- Section 1: What's broken (20%)
- Section 2: Why it matters (20%)
- Section 3: The alternative (30%)
- Section 4: How to start (15%)
- Closing: Transformation + CTA (5%)

Each section needs:
- One sentence summary
- Key sub-points (max 3)
- Transition to next section
- Source or example to include
```

**Expected output:** Complete architectural blueprint ready for drafting.

---

### 13. The Evidence Hunter
**Use when:** Making claims without backing

```
For the claim "[STATEMENT]", find:
- 2 academic studies (author, year, key finding)
- 1 industry report (source, metric, date)
- 1 counter-example or nuance
- 1 anecdote or case study

If you can't find support, flag the claim as opinion, not fact.
```

**Expected output:** Cited evidence or clear flag that claim needs softening.

---

### 14. The Headline Lab
**Use when:** You need clickable titles that deliver

```
Generate 20 headlines for [CONTENT]:

- 5 How-to ("How to X without Y")
- 5 List ("N ways to X")
- 5 Question ("Why does X happen?")
- 5 Bold promise ("The X that changes everything")

Each must:
- Pass the "so what?" test
- Be specific enough to be useful
- Avoid clickbait (must deliver on promise)
- Work for [TARGET PLATFORM]
```

**Expected output:** 20 platform-optimized headlines with variety.

---

### 15. The Conversation Simulator
**Use when:** Preparing for difficult discussions

```
Simulate a conversation where I need to [OBJECTIVE] with [PERSON TYPE].

Their likely objections:
- [OBJECTION 1]
- [OBJECTION 2]
- [OBJECTION 3]

Role-play 3 rounds:
Round 1: They raise objection, I respond
Round 2: They escalate or shift, I adapt
Round 3: Resolution or impasse

Give feedback on my responses: what worked, what backfired, better alternatives.
```

**Expected output:** Simulated dialogue with tactical feedback.

---

### 16. The FAQ Generator
**Use when:** Launching something new

```
Generate 10 FAQ entries for [PRODUCT/SERVICE/CHANGE]:

- 3 objections (why this won't work for me)
- 3 logistics (how it actually works)
- 3 comparisons (vs alternatives)
- 1 edge case (weird scenario)

Each answer must:
- Address the real concern (not just the surface question)
- Be under 75 words
- Include specific detail (not generic reassurance)
```

**Expected output:** Practical FAQ handling real friction points.

---

### 17. The Email Triager
**Use when:** Inbox overwhelm

```
Help me process this email: [PASTE EMAIL]

Classify:
- Type: [Action required / FYI / Delegation / Archive]
- Urgency: [Now / Today / This week / Someday]
- Energy required: [Low / Medium / High]
- Can it be 2-minute rule?

Draft response if needed:
- Under 5 sentences
- Clear next step or explicit no-action
- Template-able for similar messages?
```

**Expected output:** Classification + drafted response ready to send.

---

## Category 3: Research & Analysis (8 prompts)

### 18. The Gap Finder
**Use when:** Reviewing literature on a topic

```
Based on these sources: [PASTE BIBLIOGRAPHY/SUMMARIES]

Identify:
1. What's well-established (consensus)
2. What's contested (active debate)
3. What's missing (nobody studying)
4. Methodological patterns (how people study this)
5. Where the bodies are buried (findings that contradict the narrative)

Suggest one high-value research question in the gap.
```

**Expected output:** Landscape map with clear opportunity zone.

---

### 19. The Pattern Extractor
**Use when:** You have raw data without insight

```
Analyze: [PASTE DATA/NOTES/OBSERVATIONS]

Extract:
- Recurring patterns (what happens repeatedly)
- Anomalies (what breaks the pattern)
- Correlations (what moves together)
- Causal hypotheses (what might cause what)
- Predictive indicators (what signals what's coming)

Distinguish signal from noise. Flag confidence level for each.
```

**Expected output:** Pattern map with confidence annotations.

---

### 20. The Framework Matcher
**Use when:** You need the right mental model

```
For [SITUATION], suggest 3-5 applicable frameworks:

For each:
- Name and origin
- Core mechanism
- When it applies (conditions)
- When it fails (boundaries)
- How to apply it here (specific translation)

Prioritize lesser-known frameworks over obvious ones (SWOT, Porter's Five Forces).
```

**Expected output:** Framework menu with applicability analysis.

---

### 21. The Assumption Auditor
**Use when:** You're operating on autopilot

```
For [PLAN/BELIEF/SYSTEM], list:

Explicit assumptions (stated openly)
Implicit assumptions (unstated, taken for granted)
Hidden assumptions (so embedded they're invisible)

For each implicit/hidden assumption:
- What would need to be true for this to hold?
- What evidence supports/denies it?
- What if it's wrong?

Flag 3 assumptions most worth testing.
```

**Expected output:** Assumption inventory with risk prioritization.

---

### 22. The Stakeholder Mapper
**Use when:** Navigating complex organizational dynamics

```
Map stakeholders for [SITUATION/PROJECT]:

For each key player:
- Formal role vs actual influence
- What they want (stated goal)
- What they need (underlying driver)
- Their constraint (what limits them)
- Their lever (what they control)
- Relationship to other stakeholders (ally, rival, neutral)

Identify:
- Hidden power centers
- Coalition opportunities  
- Potential blockers and their price
```

**Expected output:** Influence map with tactical recommendations.

---

### 23. The Counterfactual Explorer
**Use when:** Analyzing past decisions

```
For [DECISION/EVENT], explore:

1. What actually happened (baseline)
2. What almost happened (near-miss alternative)
3. What could have happened with one variable changed
4. What we thought would happen (predicted)
5. What was unknowable at the time

Lesson extraction: What should we do differently next time vs what was genuinely unforeseeable?
```

**Expected output:** Counterfactual scenarios with calibrated learning.

---

### 24. The Optionality Analyzer
**Use when:** Evaluating strategic choices

```
Compare [OPTION A] vs [OPTION B]:

Criteria:
- Upside potential (best case)
- Downside protection (worst case)
- Reversibility (can we undo?)
- Information value (what do we learn?)
- Optionality preservation (does it keep future options open?)
- Resource efficiency (bang for buck)

Score 1-5 each. Identify dominated options. If tie, preference for reversibility.
```

**Expected output:** Decision matrix with clear recommendation.

---

### 25. The Second-Order Tracker
**Use when:** First-order thinking isn't enough

```
For [ACTION/DECISION], trace consequences:

First-order: Immediate direct effects
Second-order: Effects of the effects
Third-order: Systemic shifts
Fourth-order: Cultural/paradigm changes

At each level, identify:
- Who gains, who loses
- Time delay (immediate vs delayed)
- Probability (certain vs speculative)
- Reversibility

Where do we lose control of outcomes?
```

**Expected output:** Cascade map showing where intervention points exist.

---

## Category 4: Coding & Technical (7 prompts)

### 26. The Bug Archaeologist
**Use when:** Stuck on a stubborn bug

```
I'm debugging [ISSUE] in [CONTEXT].

Systematic approach:
1. What's the observed behavior vs expected?
2. What changed between working and broken?
3. What's the minimal reproduction case?
4. What have I already ruled out?
5. What assumptions am I making about the system?

For each component in the chain, identify:
- What's verified working
- What's suspicious
- How to isolate it

Don't solve yet—just map the terrain.
```

**Expected output:** Structured bug map with isolation strategy.

---

### 27. The Refactoring Guide
**Use when:** Code works but hurts to read

```
Refactor: [PASTE CODE]

Goals:
- Single Responsibility Principle (one reason to change)
- Clear naming (no comments needed)
- Early returns (reduce nesting)
- Explicit over implicit
- Testable units

Don't change behavior. Show before/after with line count.
```

**Expected output:** Cleaner code preserving all functionality.

---

### 28. The API Designer
**Use when:** Building interfaces others will use

```
Design an API for [FUNCTIONALITY]:

Endpoints needed:
- [List with HTTP methods]

For each endpoint:
- Input validation rules
- Success response format
- Error response formats (be specific)
- Rate limiting considerations
- Authentication requirements

Constraints:
- Keep it under 7 endpoints
- No breaking changes possible
- Idempotent where appropriate
- Clear error messages
```

**Expected output:** API specification ready for implementation.

---

### 29. The Test Strategist
**Use when:** Unclear what to test

```
For [CODE/MODULE], design test coverage:

Unit tests (fast, isolated):
- [Specific function + edge cases]

Integration tests (component interaction):
- [Cross-module scenarios]

End-to-end tests (user journey):
- [Critical paths only]

What NOT to test:
- [Third-party internals]
- [Trivial getters/setters]
- [Already covered by type system]

Priority order: What breaks most → What costs most → What users care about
```

**Expected output:** Test plan with explicit priorities and anti-patterns.

---

### 30. The Performance Detective
**Use when:** Something is slow

```
[CODE/SYSTEM] is slow under [CONDITIONS].

Diagnostic sequence:
1. Where's the bottleneck? (measure, don't guess)
2. Is it CPU, memory, I/O, or network bound?
3. What's the Big O complexity?
4. Are we doing unnecessary work?
5. Can we trade space for time?
6. Can we cache?
7. Can we parallelize?

Suggest 3 fixes in order of impact/effort ratio.
```

**Expected output:** Bottleneck identification with prioritized fixes.

---

### 31. The Security Scanner
**Use when:** Code touches user data

```
Review [CODE] for:
- Injection vulnerabilities (SQL, command, template)
- Authentication gaps
- Authorization bypasses
- Data exposure (logging, errors)
- Dependency risks
- Secrets management

For each issue found:
- Severity (Critical/High/Medium/Low)
- Exploit scenario
- Fix recommendation
- Verification approach
```

**Expected output:** Security audit with actionable remediation.

---

### 32. The Documentation Writer
**Use when:** Code needs explanation

```
Document [CODE/MODULE/API] for [AUDIENCE]:

Structure:
1. What it does (one sentence)
2. When to use it (scenarios)
3. How to use it (minimal example)
4. How it works (high-level architecture)
5. Edge cases and limitations
6. Common mistakes

Tone: [Helpful peer / Technical authority / Friendly guide]
No implementation details unless they affect usage.
```

**Expected output:** User-focused documentation.

---

## Category 5: Business & Strategy (8 prompts)

### 33. The Unit Economics Calculator
**Use when:** Evaluating business models

```
For [BUSINESS/PRODUCT], calculate:

Revenue side:
- Customer Acquisition Cost (CAC)
- Average Revenue Per User (ARPU)
- Lifetime Value (LTV)
- Payback period

Cost side:
- Fixed costs (per month)
- Variable costs (per unit)
- Contribution margin
- Break-even volume

Key ratios:
- LTV/CAC (target > 3)
- Gross margin (target > 60% for software)
- Monthly burn rate
- Runway at current spend

Sensitivity: What if CAC increases 50%? What if conversion drops 30%?
```

**Expected output:** Economics model with sensitivity analysis.

---

### 34. The Positioning Drill
**Use when:** Your message is muddy

```
For [PRODUCT/SERVICE], answer:

1. Who is it for? (specific persona, not "everyone")
2. What problem does it solve? (pain, not feature)
3. What outcome does it create? (transformation)
4. Why you and not alternatives? (differentiation)
5. Why now? (urgency trigger)

Test: Can a stranger understand all 5 in 10 seconds?

Refine until every word earns its place.
```

**Expected output:** Tight positioning statement ready for marketing.

---

### 35. The Pricing Architect
**Use when:** Unclear what to charge

```
For [OFFERING], design pricing:

Value metric: What unit captures customer value?
Tiers:
- Free/Entry: What hooks them? (limit: usage, features, or support)
- Core: What 80% need? (target price point)
- Premium: Who pays 5-10x? (what justifies it?)

Pricing psychology:
- Anchoring (what's the comparison?)
- Decoy (which tier do we want them to choose?)
- Endowment (can they try before buy?)

Alternative models to consider:
- Usage-based vs flat rate
- Seat-based vs outcome-based
- One-time vs recurring

Recommendation with rationale.
```

**Expected output:** Pricing structure with psychological rationale.

---

### 36. The Customer Interview Guide
**Use when:** You need to learn from users

```
Design an interview for [HYPOTHESIS] with [CUSTOMER TYPE]:

Opening (build rapport):
- [2-3 warm-up questions]

Problem exploration (past behavior, not hypotheticals):
- [3-4 questions about how they currently solve it]
- [What have they tried? What failed?]

Solution reaction (show prototype/concept):
- [3-4 questions about their response]
- [What would make them buy today?]

Closing:
- [Permission to follow up]
- [Referral request]

Forbidden words: "Would you..." (ask about past, not future)
```

**Expected output:** Interview script optimized for insight extraction.

---

### 37. The Competitive Intel Brief
**Use when:** Entering a crowded market

```
Analyze [COMPETITOR/COMPETITORS]:

Product:
- Core offering (what they sell)
- Positioning (how they talk about it)
- Strengths (what they do well)
- Weaknesses (where they're vulnerable)

Business:
- Revenue model (how they make money)
- Pricing (what they charge)
- Target customer (who they serve)
- Go-to-market (how they acquire)

Strategy:
- What they're optimizing for
- Recent moves and implications
- Likely next steps
- Where they're exposed

Our opportunity: [Specific gap or angle]
```

**Expected output:** Strategic intelligence with actionable opportunities.

---

### 38. The Retention Analyzer
**Use when:** Users are leaving

```
For [PRODUCT], analyze churn:

Cohort analysis:
- Day 1 retention
- Day 7 retention
- Day 30 retention
- Day 90 retention

Drop-off points:
- Where in the journey do users quit?
- What actions do quitters take before leaving?
- What actions do retainers take that quitters don't?

Root cause hypotheses:
- Onboarding failure (don't understand value)
- Value failure (expected ≠ delivered)
- Habit failure (didn't integrate into workflow)
- Better alternative (found substitute)

Retention experiments to run:
- [3 specific tests with success metrics]
```

**Expected output:** Retention diagnosis with experiment backlog.

---

### 39. The Partnership Evaluator
**Use when:** Considering a deal

```
Evaluate partnership with [PARTNER]:

Strategic fit:
- What do they have that we need?
- What do we have that they need?
- Is this mutual or one-sided?

Risk assessment:
- What could they do that would hurt us?
- What's our leverage if things go wrong?
- Can we start small and scale?

Terms to negotiate:
- Exclusivity (avoid if possible)
- Termination rights (keep exit options)
- IP ownership (clarify upfront)
- Performance commitments (both sides)

Decision: Proceed / Proceed with caution / Decline
```

**Expected output:** Partnership assessment with negotiation priorities.

---

### 40. The Pivot Detector
**Use when:** Something isn't working

```
For [SITUATION], evaluate pivot options:

Current trajectory:
- What's working (keep)
- What's not working (change or kill)
- What's unclear (test)

Pivot types to consider:
- Zoom-in (focus on one feature that's working)
- Zoom-out (platform play)
- Customer segment (same product, different buyer)
- Customer need (same buyer, different problem)
- Platform (become infrastructure)
- Business model (how you make money)

Requirements for each pivot:
- Evidence it could work
- Resources required
- Time to validate
- Downside if wrong

Recommendation with go/no-go criteria.
```

**Expected output:** Pivot analysis with decision framework.

---

## Category 6: Personal Productivity (7 prompts)

### 41. The Priority Filter
**Use when:** Everything feels urgent

```
I have these tasks: [LIST]

Apply filters:
1. Impact: What moves the needle most?
2. Urgency: What has real deadline (not just anxiety)?
3. Leverage: What unlocks other work?
4. Energy: What matches my current capacity?
5. Delegation: What can only I do?

Rank top 3. Everything else is "later" (not never, just not now).
```

**Expected output:** Ruthlessly prioritized task list.

---

### 42. The Energy Auditor
**Use when:** You feel drained but busy

```
Review my week: [ACTIVITIES/TASKS]

Classify each:
- Energy giving (+) vs energy draining (-)
- Essential (must happen) vs discretionary (optional)
- High skill (uses my strengths) vs low skill (anyone could do)

Patterns to find:
- What time of day am I most energized?
- What tasks consistently drain me?
- What's essential but draining? (delegate or redesign)
- What's energizing but discretionary? (do more)

One change to make this week:
```

**Expected output:** Energy map with one actionable change.

---

### 43. The Habit Designer
**Use when:** Building new routines

```
Design a habit for [BEHAVIOR]:

Cue: What triggers the behavior? (time, location, preceding action)
Craving: How do I make it attractive? (pair with something I want)
Response: What's the smallest viable version? (2-minute rule)
Reward: What's the immediate payoff? (completion check, small treat)

Friction reduction:
- What makes this hard now?
- How do I remove 2 steps?
- What's the environment design?

Accountability:
- Who will I tell?
- How will I track?
- What's the consequence for missing?
```

**Expected output:** Habit implementation plan using behavioral science.

---

### 44. The Delegation Planner
**Use when:** Overwhelmed with tasks

```
For each task: [LIST]

Can it be delegated?
- Yes: Who? What's the brief? What's the deadline?
- No: Why? (skill, context, decision rights, relationship)

For delegable tasks, write the brief:
- Outcome desired (not process)
- Constraints (budget, time, quality)
- Success criteria (how I know it's done)
- Check-in schedule (how often to sync)
- Authority level (decisions they can make)

What I keep: Only what requires my unique judgment or relationships.
```

**Expected output:** Delegation plan with clear briefs.

---

### 45. The Meeting Optimizer
**Use when:** Too many meetings

```
For [MEETING/MEETING PROPOSAL], decide:

Purpose: What decision or outcome is needed?
Required: Who absolutely must be there?
Format: Sync (real-time) vs async (document)?
Length: What's the minimum time to achieve purpose?
Prep: What do people need to review beforehand?

If proceeding, design the agenda:
- Opening: Context (2 min)
- Middle: Discussion structured around decisions (not updates)
- Closing: Clear next steps with owners and deadlines

If canceling, communicate: What they'll get async instead.
```

**Expected output:** Optimized meeting design or cancellation rationale.

---

### 46. The Goal Decomposer
**Use when:** Goals feel overwhelming

```
Decompose [GOAL] into executable chunks:

Outcome goal: [End state]
Process goals: [Daily/weekly actions that lead to outcome]
Milestone 1 (week 1): [Concrete deliverable]
Milestone 2 (week 2): [Concrete deliverable]
...

For each milestone:
- What's the specific deliverable?
- How will I know it's done?
- What could block it?
- What's my plan B?

Keep milestones under 1 week. If bigger, decompose further.
```

**Expected output:** Executable roadmap with clear milestones.

---

### 47. The Review Protocol
**Use when:** Learning from experience

```
Review [PERIOD/PROJECT/EXPERIENCE]:

What happened? (objective facts)
What did I expect? (my prior model)
What was the delta? (surprises)
What was my role? (agency, not blame)
What would I do differently? (specific, not generic)
What will I actually change? (one thing, starting when)

Pattern check:
- Is this a recurring mistake?
- What's the underlying cause?
- What system would prevent it?
```

**Expected output:** Calibrated learning with concrete next action.

---

## How to Use This Pack

### Quick Start
1. **Bookmark this page** — you'll return to it
2. **Pick 3 prompts** that solve your current pain points
3. **Use them daily for a week** — build the muscle
4. **Iterate** — modify prompts to match your voice

### Advanced Usage
- **Chain prompts:** Use #7 (Synthesis) on outputs from #2 (Recursive Analysis)
- **Build templates:** Save modified versions in your notes app
- **Track ROI:** Note which prompts save you time vs which just feel useful

### The Meta-Prompt
When in doubt, use this:

```
I'm [SITUATION]. I need [OUTCOME].
My constraints are [LIMITS].
What would you ask me to clarify before helping?
```

The best prompts emerge from dialogue, not templates.

---

## Changelog

**v1.0 (2026-02-10)** — Initial release
- 47 prompts across 6 categories
- Focus on knowledge work (writing, research, coding, strategy)
- Battle-tested over 6 months of daily use

---

## License & Usage

**Personal use:** Unlimited  
**Team use:** Purchase one copy per 5 team members  
**Resale/derivative works:** Prohibited

---

**Built by:** AGNI Research + DC Editorial  
**Questions?** Reply to your Gumroad receipt  
**Updates:** Free for life

---

*"The right prompt is worth 100 hours of brute force."*
