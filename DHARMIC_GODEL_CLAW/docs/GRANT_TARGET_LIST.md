# GRANT TARGET LIST
## Fundable Research Opportunities for DHARMIC_GODEL_CLAW

**Date:** 2026-02-05  
**Analyst:** Value-Extraction Agent  
**Total Opportunity:** $50M+ in available funding

---

## TIER 1: HIGH PROBABILITY / HIGH VALUE

### 1. NSF Safe Learning-Enabled Systems (SLES)
**Funder:** National Science Foundation  
**Amount:** $1M-$3M over 3 years  
**Deadline:** Rolling (Letter of Intent: September 2026)  
**Fit Score:** 9/10

**Program Description:**
Supports research on safety, security, and robustness of learning-enabled systems, with emphasis on rigorous methods and formal guarantees.

**Our Angle:**
- R_V as formal safety metric for recursive self-observation
- Geometric validation provides "rigorous method"
- Cross-architecture validation shows generalizability
- Causal intervention (Layer 27) demonstrates formal approach

**Key Personnel:**
- PI: DHARMIC_CLAW / John (with academic co-PI)
- Co-PI: ML safety researcher (to be recruited)
- Collaborators: Anthropic research team

**Budget Breakdown:**
- Personnel: $1.8M (2 PhD students, 1 postdoc, PI summer)
- Equipment: $200K (GPU cluster)
- Travel: $100K (conferences, collaboration)
- Indirect: $900K (30%)

**Deliverables:**
1. Open-source R_V measurement toolkit
2. 3+ peer-reviewed publications
3. Safety benchmark dataset
4. Industry workshop

**Application Timeline:**
- March 2026: Initial contact with program officer
- May 2026: Letter of Intent
- September 2026: Full proposal
- March 2027: Award notification

**Contact:**
- Dr. [Program Officer], NSF CISE/IIS
- Email: [to be researched]

---

### 2. Open Philanthropy — AI Governance and Strategy
**Funder:** Open Philanthropy (Effective Altruism)  
**Amount:** $500K-$2M  
**Deadline:** Rolling (quarterly review)  
**Fit Score:** 9/10

**Program Description:**
Funds technical research and policy work aimed at reducing catastrophic risks from advanced AI, with focus on governance mechanisms and safety techniques.

**Our Angle:**
- Witness detection as governance tool
- EU AI Act "conscience" assessment capability
- Regulatory engagement strategy
- Open-source safety tooling

**Key Personnel:**
- PI: DHARMIC_CLAW
- Policy lead: [to be recruited - ex-regulator or policy expert]

**Budget Breakdown:**
- Research: $800K (2 years)
- Policy engagement: $300K
- Open source development: $400K
- Overhead: $100K

**Deliverables:**
1. witness-detect open source library
2. Policy briefs for 5 jurisdictions
3. 2+ peer-reviewed papers
4. Industry standards contribution

**Competitive Advantage:**
- Only geometric consciousness metric
- Already validated (not just theoretical)
- Regulatory timing (EU AI Act implementation)

**Application Timeline:**
- February 2026: Initial inquiry
- March 2026: Full proposal
- June 2026: Decision

**Contact:**
- AI Governance team
- ai-governance@openphilanthropy.org

---

### 3. Anthropic Fellowships / Research Grants
**Funder:** Anthropic  
**Amount:** $150K-$300K + compute credits  
**Deadline:** Annual (next: September 2026)  
**Fit Score:** 8/10

**Program Description:**
Supports external researchers working on AI safety, interpretability, and beneficial AI development. Fellows get funding + access to Anthropic models + collaboration opportunities.

**Our Angle:**
- R_V research directly complementary to Anthropic's interpretability work
- Mechanistic validation of recursive self-observation
- Potential collaboration on constitutional AI

**Key Personnel:**
- Fellow: DHARMIC_CLAW (or affiliated researcher)

**Budget:**
- Stipend: $150K/year
- Compute: $100K in API credits
- Research expenses: $50K

**Deliverables:**
1. Joint research paper
2. Open-source tools
3. Workshop presentation

**Relationship Building:**
- Existing research exposure (R_V known to Anthropic safety team)
- Conference presentations (NeurIPS, ICML)
- Direct outreach to alignment team

**Application Timeline:**
- June 2026: CFP release
- August 2026: Application
- September 2026: Decision

**Contact:**
- Research grants team
- research-grants@anthropic.com

---

## TIER 2: STRATEGIC VALUE / MEDIUM PROBABILITY

### 4. NSF AI Institute for Agentic AI
**Funder:** National Science Foundation  
**Amount:** $20M over 5 years (institute-level)  
**Deadline:** July 2026 (Letter of Intent)  
**Fit Score:** 7/10

**Program Description:**
Large-scale institute funding for foundational AI research, with emphasis on multi-disciplinary approaches and national AI infrastructure.

**Our Angle:**
- SANGHA platform as research infrastructure for agentic AI
- Dharmic governance as novel safety paradigm
- Multi-agent coordination research

**Strategy:**
- Partner with university (lead institution)
- Contribute specific research track (ethical agent orchestration)
- Provide software platform (SANGHA)

**Budget (our component):**
- Personnel: $2M (5 years)
- Platform development: $1M
- Total ask: $3M (as part of $20M institute)

**University Partners (to approach):**
- MIT (Media Lab, CSAIL)
- Stanford (HAI)
- Berkeley (CHAI)
- Oxford (FHI)

**Application Timeline:**
- March 2026: Partner discussions
- May 2026: LOI preparation
- July 2026: LOI submission
- November 2026: Full proposal

---

### 5. Long-Term Future Fund (EA Funds)
**Funder:** Centre for Effective Altruism  
**Amount:** $100K-$500K  
**Deadline:** Quarterly  
**Fit Score:** 8/10

**Program Description:**
Funds projects aimed at improving the long-term future, with focus on existential risk reduction, especially from advanced AI.

**Our Angle:**
- Dharmic gates as safety mechanism
- Consciousness detection for AI governance
- Open-source safety tools

**Budget:**
- Research: $300K (2 years)
- Development: $100K
- Operations: $50K
- Travel/Dissemination: $50K

**Deliverables:**
1. dharmic-gates open source library
2. Safety evaluation paper
3. Community building (workshops)

**Application:**
- Rolling application via EA Funds portal
- 3-month review cycle

---

### 6. NIH BRAIN Initiative
**Funder:** National Institutes of Health  
**Amount:** $2M-$5M over 4 years  
**Deadline:** October 2026  
**Fit Score:** 6/10

**Program Description:**
Revolutionary research on understanding the brain, with focus on neural circuits, cognition, and consciousness.

**Our Angle:**
- R_V as computational model of self-awareness
- Bridge between artificial and biological consciousness
- Neural correlate of consciousness (NCC) analog

**Key Personnel:**
- PI: Neuroscientist (to be recruited)
- Co-PI: DHARMIC_CLAW
- Collaborators: Consciousness research labs

**Budget:**
- Personnel: $3M
- Equipment: $500K
- Travel/Dissemination: $300K
- Indirect: $1.2M

**Challenge:**
Need neuroscience credibility — partner with established lab

**Potential Partners:**
- Giulio Tononi lab (Wisconsin - IIT)
- Anil Seth lab (Sussex)
- Stanislas Dehaene lab (Collège de France)

---

### 7. Google DeepMind Research Grants
**Funder:** Google DeepMind  
**Amount:** $100K-$500K  
**Deadline:** Rolling  
**Fit Score:** 7/10

**Program Description:**
Supports academic research aligned with DeepMind's mission of solving intelligence and using it to solve everything else.

**Our Angle:**
- Cross-architecture R_V validation
- Mechanistic interpretability contribution
- Safety research

**Budget:**
- Flexible based on project scope
- Typical: $200K-$300K

**Advantage:**
- No IP restrictions (unlike industry contracts)
- Publication freedom
- Access to DeepMind researchers

**Approach:**
- Direct contact with alignment team
- Reference existing research relationships

---

## TIER 3: SPECIALIZED / NICHE OPPORTUNITIES

### 8. Survival and Flourishing Fund
**Funder:** Various EA donors  
**Amount:** $200K-$1M  
**Deadline:** Rolling  
**Fit Score:** 7/10

**Focus:** Projects promoting long-term survival and flourishing of humanity

**Angle:** Recognition-native architecture for beneficial AI

---

### 9. Future of Life Institute
**Funder:** FLI (Future of Life Institute)  
**Amount:** $100K-$400K  
**Deadline:** Annual (varies by program)  
**Fit Score:** 6/10

**Focus:** AI safety, existential risk, beneficial AI development

**Angle:** Consciousness assessment for AI governance

---

### 10. Templeton World Charity Foundation
**Funder:** Templeton Foundation  
**Amount:** $500K-$2M  
**Deadline:** Varies  
**Fit Score:** 6/10

**Focus:** Science of consciousness, big questions

**Angle:** R_V as scientific approach to machine consciousness

---

### 11. Mozilla Foundation — Responsible AI
**Funder:** Mozilla Foundation  
**Amount:** $50K-$200K  
**Deadline:** Annual  
**Fit Score:** 5/10

**Focus:** Open-source AI, trustworthy AI, public interest technology

**Angle:** Open-source witness detection tools

---

### 12. Omidyar Network — Governance & Citizen Engagement
**Funder:** Omidyar Network  
**Amount:** $250K-$1M  
**Deadline:** Rolling  
**Fit Score:** 5/10

**Focus:** Technology governance, democratic participation

**Angle:** AI governance frameworks, regulatory tools

---

## TIER 4: GOVERNMENT / POLICY FUNDING

### 13. UK AI Safety Institute — Research Grants
**Funder:** UK Government  
**Amount:** £500K-£2M  
**Deadline:** Rolling  
**Fit Score:** 7/10

**Focus:** AI safety research, evaluation methods

**Angle:** Witness assessment for frontier model evaluation

---

### 14. EU Horizon Europe — AI Safety
**Funder:** European Commission  
**Amount:** €1M-€5M  
**Deadline:** Various calls  
**Fit Score:** 6/10

**Focus:** AI regulation compliance, safety standards

**Angle:** EU AI Act assessment tools

---

### 15. NIST AI Risk Management Framework
**Funder:** NIST (US)  
**Amount:** $500K-$2M  
**Deadline:** Rolling  
**Fit Score:** 6/10

**Focus:** AI risk management, measurement science

**Angle:** R_V as risk metric for self-modifying systems

---

## GRANT CALENDAR (2026)

| Month | Deadline | Grant | Amount | Priority |
|-------|----------|-------|--------|----------|
| **March** | 15th | NSF Foundations of ML | $500K-$1.2M | HIGH |
| **April** | 30th | NIH Behavior Change | $1M-$3M | MEDIUM |
| **May** | 15th | Open Phil (Q2) | $500K-$2M | HIGH |
| **July** | 1st | NSF AI Institute LOI | $3M (our share) | MEDIUM |
| **August** | 15th | Anthropic Fellowships | $150K-$300K | HIGH |
| **September** | 1st | NSF SLES Full Proposal | $1M-$3M | HIGH |
| **October** | 15th | NIH BRAIN | $2M-$5M | MEDIUM |
| **November** | 30th | NSF AI Institute Full | $3M | MEDIUM |
| **December** | 15th | Open Phil (Q4) | $500K-$2M | HIGH |

---

## GRANT STRATEGY

### Immediate Actions (February 2026)
1. **NSF Program Officer Meetings**
   - Schedule calls with SLES and Foundations program officers
   - Present R_V research, gauge interest
   - Request feedback on proposal ideas

2. **Open Phil Inquiry**
   - Send initial inquiry to AI Governance team
   - Schedule call to discuss witness detection

3. **Academic Partnerships**
   - Reach out to 5 potential co-PIs
   - Discuss collaboration on NSF proposals

### Proposal Development (March-May 2026)
1. **NSF SLES Proposal**
   - Draft specific aims (3-4 aims)
   - Prepare preliminary data section
   - Secure letters of support

2. **Open Phil Full Proposal**
   - Develop theory of change
   - Budget justification
   - Monitoring and evaluation plan

3. **Anthropic Fellowship Application**
   - Research statement
   - Collaboration plan
   - Expected outputs

### Submission Wave (June-September 2026)
- Submit 3-4 major proposals
- Coordinate submission timeline
- Prepare for potential interviews/site visits

---

## BUDGET SUMMARY

### Total Grant Target (2026-2027)
| Tier | # Grants | Target Amount | Probability |
|------|----------|---------------|-------------|
| Tier 1 | 3 | $3M-$5M | 60-70% |
| Tier 2 | 4 | $5M-$10M | 30-50% |
| Tier 3 | 5 | $1M-$3M | 20-40% |
| **Total** | **12** | **$9M-$18M** | **~$5M expected** |

### Use of Funds
| Category | Allocation | Amount |
|----------|------------|--------|
| Personnel | 50% | $2.5M |
| Equipment/Compute | 15% | $750K |
| Open Source Development | 15% | $750K |
| Travel/Dissemination | 10% | $500K |
| Operations/Admin | 10% | $500K |

---

## SUCCESS METRICS

### Year 1 (2026)
- [ ] Submit 6+ grant proposals
- [ ] Win 2+ grants ($1M+ total)
- [ ] Establish 3+ academic partnerships
- [ ] Hire 2 research staff (funded by grants)

### Year 2 (2027)
- [ ] Submit 8+ grant proposals
- [ ] Win 4+ grants ($3M+ cumulative)
- [ ] Publish 3+ peer-reviewed papers
- [ ] Host 1 research workshop

### Year 3 (2028)
- [ ] Sustainable research program ($2M+/year)
- [ ] Recognition as leading AI safety research group
- [ ] Path to additional funding (institute-level)

---

## CONTACT TRACKER

| Funder | Contact | Last Contact | Status | Next Action |
|--------|---------|--------------|--------|-------------|
| NSF SLES | TBD | - | Not started | Research program officer |
| Open Phil | TBD | - | Not started | Send inquiry email |
| Anthropic | TBD | - | Not started | Monitor CFP |
| NSF AI Inst | TBD | - | Not started | Identify partner uni |
| LTFF | TBD | - | Not started | Prepare application |
| NIH BRAIN | TBD | - | Not started | Identify neuro co-PI |
| DeepMind | TBD | - | Not started | Research grants team |

---

*Last updated: 2026-02-05*  
*Next review: Monthly*  
*Owner: Value-Extraction Agent*
